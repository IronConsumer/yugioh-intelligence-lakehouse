from pyspark.sql import functions as F, DataFrame
from src.utils.spark_manager import SparkManager
from src.config.schema import CardColumns as Col
from src.utils.logger import get_logger

logger = get_logger("DATA_QUALITY")

class GoldQualityChecker:
    def __init__(self) -> None:
        self.spark = SparkManager.get_session()

    def _check_volume(self, df: DataFrame) -> bool:
        """V√©rifie si le volume de donn√©es est suffisant (seuil minimal de 10).
        
        Args:
            df (DataFrame): Le DataFrame Gold √† analyser.
            
        Returns:
            bool: True si le test passe, False sinon.
        """
        count = df.count()
        if count < 10:
            logger.warning(f"‚ö†Ô∏è Volume anormalement faible : seulement {count} cartes trouv√©es.")
            return False
        return True

    def _check_price_consistency(self, df: DataFrame) -> bool:
        """V√©rifie l'absence de prix nuls ou n√©gatifs.
        
        Args:
            df (DataFrame): Le DataFrame Gold √† analyser.
            
        Returns:
            bool: True si tous les prix sont valides, False sinon.
        """
        zero_prices = (
            df.filter(
                (F.col(Col.PRICE_CM) <= 0) | 
                (F.col(Col.PRICE_TCG) <= 0)
            ).count()
        )
        if zero_prices > 0:
            logger.error(f"‚ùå {zero_prices} cartes ont un prix nul ou n√©gatif !")
            return False
        return True

    def _check_business_logic(self, df: DataFrame) -> bool:
        """Valide la coh√©rence math√©matique entre les colonnes de prix et leur diff√©rence.
        
        Args:
            df (DataFrame): Le DataFrame Gold √† analyser.
            
        Returns:
            bool: True si les calculs sont exacts, False sinon.
        """
        bad_math = (
            df.withColumn(
                "calc_diff", 
                F.round(F.abs(F.col(Col.PRICE_TCG) - F.col(Col.PRICE_CM)), 2))
              .filter("calc_diff != price_diff")
              .count()
        )
        
        if bad_math > 0:
            logger.error(f"‚ùå Erreur de calcul d√©tect√©e sur {bad_math} lignes !")
            return False
        return True

    def run_checks(self) -> bool:
        """Ex√©cute l'ensemble des tests de qualit√© sur la couche Gold.
        
        Cette m√©thode centralise les appels aux diff√©rents checks de validation 
        (Volume, Coh√©rence, Logique m√©tier) sur les opportunit√©s d'arbitrage.

        Returns:
            bool: True si tous les tests sont valid√©s, False si au moins un test √©choue.
        """
        logger.info("üß™ D√©marrage des tests de qualit√© sur la couche Gold...")
        
        df_gold = (
            self.spark.read
                .format("delta")
                .load("data/gold/arbitrage_opportunities")
        )

        # Ex√©cution des tests et agr√©gation des r√©sultats
        results = [
            self._check_volume(df_gold),
            self._check_price_consistency(df_gold),
            self._check_business_logic(df_gold)
        ]

        has_error = not all(results)

        if not has_error:
            logger.info("‚úÖ Tous les tests de qualit√© sont pass√©s avec succ√®s !")
        
        return not has_error

if __name__ == "__main__":
    checker = GoldQualityChecker()
    checker.run_checks()

